---
layout: page
title: About
permalink: /about/
---

<div class="about-hero">
<div class="about-hero-content">
<div class="about-photo">
<img src="/assets/images/profile.jpg" alt="Allen Philip J" onerror="this.parentElement.innerHTML='<div class=\'photo-placeholder\'>AP</div>'">
</div>
<div class="about-intro">
<h1>Allen Philip J</h1>
<p class="tagline">Building AI platforms & making large models run fast</p>
<p class="location">Dublin, Ireland</p>
</div>
</div>
</div>

<section class="about-numbered">
<div class="section-number">01</div>
<div class="section-content">
<h2>Background</h2>

<p>I'm a Senior Product Engineer at <a href="https://intercom.com">Intercom</a>, working on AI platforms. Previously, I spent 4 years at Adobe optimizing inference for Firefly's generative video and audio models.</p>

<p>My focus is post-training inference optimization: quantization, attention efficiency, runtime acceleration, and deep profiling. I work at the intersection of model architecture and system performance—getting the most out of inference frameworks and hardware (A100/H100).</p>

<p>I don't just run models—I make them run well.</p>

</div>
</section>

<section class="about-numbered">
<div class="section-number">02</div>
<div class="section-content">
<h2>Focus Areas</h2>

<p><strong>Attention & Kernels</strong> — Integrating FlashAttention variants, writing custom CUDA kernels, optimizing diffusion loop inference for video models.</p>

<p><strong>Quantization</strong> — INT8 and FP8 workflows, calibration strategies, navigating the accuracy-performance tradeoff for production GenAI models.</p>

<p><strong>Model Compilation</strong> — TensorRT optimization, torch.compile debugging, operator fusion strategies for real-world speedups on A100/H100.</p>

<p><strong>AI Platforms</strong> — Building self-serve ML platforms, anomaly detection systems, and scalable inference pipelines.</p>

</div>
</section>

<section class="about-numbered">
<div class="section-number">03</div>
<div class="section-content">
<h2>Experience</h2>

<div class="experience-list">
<div class="experience-item">
<div class="exp-period">2025 – Present</div>
<div class="exp-content">
<div class="exp-role">Senior Product Engineer, Intercom</div>
<div class="exp-team">AI Infrastructure</div>
<ul class="exp-details">
<li>Building AI platform infrastructure for customer support automation</li>
<li>Scaling LLM-powered features for enterprise customers</li>
</ul>
</div>
</div>
<div class="experience-item">
<div class="exp-period">2021 – 2025</div>
<div class="exp-content">
<div class="exp-role">ML Engineer 4, Adobe</div>
<div class="exp-team">Firefly Video/Audio GenAI</div>
<ul class="exp-details">
<li>Reduced inference latency by 35% via FP8 quantization and 25% via custom TRT attention plugins</li>
<li>Scaled Enhance Speech pipeline to 150 RPM on 50+ A100 GPUs; cut ops costs by 33%</li>
</ul>
</div>
</div>
<div class="experience-item">
<div class="exp-period">2016 – 2021</div>
<div class="exp-content">
<div class="exp-role">Senior ML Engineer, Blue Yonder</div>
<div class="exp-team">Promotional Demand Forecasting</div>
<ul class="exp-details">
<li>Led ML pipelines for demand modeling serving 90M+ SKUs for Walmart, Loblaws, Woolworths</li>
<li>Optimized batch processing to meet SLAs for retailers with massive product catalogs</li>
</ul>
</div>
</div>
<div class="experience-item">
<div class="exp-period">2014 – 2016</div>
<div class="exp-content">
<div class="exp-role">Software Engineer, Oracle</div>
<div class="exp-team">Cloud Commerce</div>
<ul class="exp-details">
<li>Full-stack development for B2B catalog, pricing, and user management features</li>
<li>Recipient of Best Rookie Award (2015)</li>
</ul>
</div>
</div>
</div>

<p style="margin-top: 1.5rem; font-size: 0.9rem; color: #666;">B.Tech Electrical Engineering, IIT Madras (2014)</p>

</div>
</section>

<section class="about-numbered">
<div class="section-number">04</div>
<div class="section-content">
<h2>Now</h2>

<p>Building AI platform infrastructure at Intercom. Expanding deeper into LLMs while continuing to write about inference optimization, attention mechanisms, and the practical side of ML systems.</p>

</div>
</section>

<section class="about-numbered">
<div class="section-number">05</div>
<div class="section-content">
<h2>Tools</h2>

<div class="tools-grid">
<span class="tool-tag">PyTorch</span>
<span class="tool-tag">CUDA</span>
<span class="tool-tag">TensorRT</span>
<span class="tool-tag">Triton</span>
<span class="tool-tag">Python</span>
<span class="tool-tag">C++</span>
<span class="tool-tag">Docker</span>
<span class="tool-tag">Kubernetes</span>
</div>

</div>
</section>

<section class="about-contact">
<h2>Get in touch</h2>
<p>Have a question about ML inference or want to collaborate? Feel free to reach out.</p>
<a href="mailto:allenphilip93@gmail.com" class="contact-btn">allenphilip93@gmail.com</a>
</section>
